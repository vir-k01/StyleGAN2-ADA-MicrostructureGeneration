{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-MicrostructureGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYT8RvDMZ/KMsi4vvBydLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vir-k01/StyleGAN2-ADA-MicrostructureGeneration/blob/main/GAN_MicrostructureGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microstructure Generation using a trained StyleGAN2"
      ],
      "metadata": {
        "id": "i1AWusvkkhZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code accompanying the manuscript: \"Quantification of similarity and physical awareness of microstructures generated via Generative Models\" by Sanket Thakre, Vir Karan, Anand Krishna Kanjarla.\n",
        "\n",
        "-Notebook authored by Vir Karan"
      ],
      "metadata": {
        "id": "7Et8vmEJkmUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Basics"
      ],
      "metadata": {
        "id": "HweL7st_nB4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code needed to generate new microstructural data using a trained StyleGAN2-ADA model in the Google Colab environment. The notebook needed to train the GAN is present in the same repository as this (https://github.com/vir-k01/StyleGAN2-ADA-MicrostructureGeneration/blob/main/StyleGAN2_ADA_Training.ipynb). This notebook clones the official repository by Nvidia (https://github.com/NVlabs/stylegan2-ada) and then calls the scripts from that repo. Relevant changes can be made to run this locally or on a workstation. "
      ],
      "metadata": {
        "id": "LIhllCzDkt2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StyleGAN2-ADA only work with Tensorflow 1. Run the next cell before anything else to make sure weâ€™re using TF1 and not TF2.**"
      ],
      "metadata": {
        "id": "63IdRFu7nFe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "id": "hA6wjwzpnJoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that a GPU runtime has been selected. GANs require **a lot** of compute to train, so make sure you've got a GPU with atleast 12GB RAM here. Even though we're not training a GAN here, having a GPU will be preferable since we'll be using the `dnnlib` functions next. In the case of Colab, the default K80 GPU should suffice for smaller datasets, but it is preferable to use a T4 or P100 or better GPU. We'll first clone the official StyleGAN2-ADA repo and load all the dependecies."
      ],
      "metadata": {
        "id": "UB03o1N9nPET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPUMrKGtkWoT"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "%cd stylegan2-ada\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To allow for easy  loading/saving of files, it is preferable to mount Google Drive as well. "
      ],
      "metadata": {
        "id": "Pgkb8Wotn6FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zOB8D57ioA5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies from the repo and otherwise\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "from math import ceil\n",
        "import imageio\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.image as mpimg\n",
        "from skimage import filters"
      ],
      "metadata": {
        "id": "qJCO0f85lqtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll load the trained model from Drive. Once again reiterating, **make sure a GPU is available** before going further. The `.pkl` file used can be found in our repo as well (https://drive.google.com/drive/folders/1Oz2NlycaIfK0-mebNgz5HTTW4_UuVikQ?usp=sharing)."
      ],
      "metadata": {
        "id": "LjRdhuxPn03z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan2-ada/\n",
        "\n",
        "dnnlib.tflib.init_tf() \n",
        "network_pkl = '/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada/results/00045-dam_data256-11gb-gpu-bg-resumecustom/network-snapshot-000020.pkl'\n",
        " \n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "with dnnlib.util.open_url(network_pkl) as fp:\n",
        "    _G, _D, Gs = pickle.load(fp)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ],
      "metadata": {
        "id": "wpIi2k11lwwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "These custom functions allow us to generate and post-process the microstructures. "
      ],
      "metadata": {
        "id": "4MKlCgMdoz_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])  \n",
        "\n",
        "def store_array(im, filename):\n",
        "  fil = open(str(filename) + '.txt', 'w')\n",
        "  row, column = im.shape\n",
        "  for y in range(column):\n",
        "      for x in range(row):\n",
        "          pixel = im[y, x]\n",
        "          fil.write(str(x+1) + \" \" + str(y+1) + \" \" + str(pixel) + '\\n')\n",
        "  fil.close()\n",
        "\n",
        "def load_latent(path):\n",
        "  latent = np.load(path, mmap_mode = 'r')\n",
        "  return latent['dlatents']\n",
        "\n",
        "def process_output(path, image = True):\n",
        "  img = Image.open(path)\n",
        "  return rgb2gray(np.asarray(img))/255\n",
        "\n",
        "def threshold(arr, show = True, show_pf = 0):\n",
        "  thres = filters.threshold_otsu(arr)\n",
        "  bin = []\n",
        "  for i in range(np.shape(arr)[0]):\n",
        "    for j in range(np.shape(arr)[1]):\n",
        "      if arr[i,j]> thres:\n",
        "        bin.append(1)\n",
        "      else:\n",
        "        bin.append(0)\n",
        "  bin = np.reshape(np.asarray(bin), (256, 256))\n",
        "  pf = np.sum(bin)/(256*256)\n",
        "  if show_pf:\n",
        "    print('pf: ' + str(pf))\n",
        "  if show:\n",
        "    plt.imshow(bin, cmap = 'gray')\n",
        "  return bin, pf\n",
        "\n",
        "def generate_from_latent(latent, psi =0.7, show = True, save =False):\n",
        "  imgs = Gs.components.synthesis.run(latent, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "  im, pf = threshold(rgb2gray(imgs[0]), show = show)\n",
        "  if show:\n",
        "    plt.imshow(np.asarray(im), cmap = 'gray')\n",
        "  if save:\n",
        "    plt.imsave('output_'+ str(psi), np.asarray(im))\n",
        "    imageio.imwrite('output_'+ str(psi), np.asarray(im))\n",
        "  return np.asarray(im)\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "def make_grid(img, rows, cols):\n",
        "  fig = plt.figure(figsize=(40., 40.))\n",
        "  grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                  nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n",
        "                  axes_pad=0.1,  # pad between axes in inch.\n",
        "                  )\n",
        "\n",
        "  for ax, im in zip(grid, img):\n",
        "      # Iterating over the grid returns the Axes.\n",
        "      ax.imshow(im, cmap='gray')\n",
        "\n",
        "def generate_images_direction(latent, direction, distance, scale, show =1, compare =0):\n",
        "  latent1 = latent + direction*scale*distance \n",
        "  imgs = Gs.components.synthesis.run(latent1, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "  img, pf = threshold(rgb2gray(imgs[0]), show = show)\n",
        "  if compare:\n",
        "    img0 = Gs.components.synthesis.run(latent, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "    img0, pf1 = threshold(rgb2gray(img0[0]), show = show)\n",
        "    compare_image(img0, img, '')\n",
        "  return img\n",
        "\n",
        "def generate_n_images(latent, n=5, show = 1, noise=1):\n",
        "  out = []\n",
        "  for i in range(n):\n",
        "    latent1 = latent + 0.01*np.random.randn(1, 14, 512)*noise\n",
        "    imgs = Gs.components.synthesis.run(latent1, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "    img, pf = threshold(rgb2gray(imgs[0]), show = show)\n",
        "    out.append(img)\n",
        "  return out"
      ],
      "metadata": {
        "id": "IaCrUqqglx98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projecting to the latent space"
      ],
      "metadata": {
        "id": "CfhOgH8ZpjOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going further, in order to have control over the microstructures that are generated, we'll have to project our target microstructures into the trained GAN's latent space and get a latent code (section 2.2 of the manuscript). This process has to be done only once. You can skip this if you've got the latent code for the target microstructure you want. Regardless, a random (1, 14, 512) vector can also be used to generate microstructures.\n",
        "\n",
        "Just define lists with the class_id and the indices of the microstructures whose latent representations you need. "
      ],
      "metadata": {
        "id": "Fhkaej43pm5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_id = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6]\n",
        "index = [1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]"
      ],
      "metadata": {
        "id": "Gm-DfCgBl2cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll now use the `projector.py` script from the repo to perform the projection. You can check the arguements for this script by running the next cell."
      ],
      "metadata": {
        "id": "EB-iqiHgqU95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python projector.py -h"
      ],
      "metadata": {
        "id": "fmAj_dpxl7ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the trained model with the \"network\" tag, loop over all the classes and project one microstructure from each class using the \"target tag\" to get a \"representative\" latent vector for that class and save in the \"outdir\" tag.\n",
        "\n",
        "Note: each microstructure would take around 2-5 min on a T4 GPU to project into the latent space."
      ],
      "metadata": {
        "id": "KYW1Mi1pmDZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(index, class_id):\n",
        "  !python projector.py --outdir='/content/drive/MyDrive/GAN/Damage prediction/Out/latents/'{i}'_class_'{j}'/' --target='/content/drive/MyDrive/GAN/damage_data/'{50*(j-1)+(i-1)}'.jpeg' --network='/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada/results/00045-dam_data256-11gb-gpu-bg-resumecustom/network-snapshot-000020.pkl'\n",
        "  print('Finished: '+ str(i)+' '+ str(j))"
      ],
      "metadata": {
        "id": "5nRKb8Oll_sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've put up the latent vectors corresponding to the microstructures of our study on the repo as well (https://drive.google.com/drive/folders/1Oz2NlycaIfK0-mebNgz5HTTW4_UuVikQ?usp=sharing)."
      ],
      "metadata": {
        "id": "fnsrTMAzsXyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An example showing how to generate microstructures using the latent vector and the trained model\n",
        "\n"
      ],
      "metadata": {
        "id": "tW4CeJ4HmNfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't have a latent code already, just sample a (1, 14, 512) dimension vector from a Gaussian and use that as the latent vector. Here, we'll use the latent vector for Class 5. "
      ],
      "metadata": {
        "id": "2d6vanPAmVSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat = np.load('/content/drive/MyDrive/GAN/Vir files/Damage prediction/Out/latents/14_class_5/dlatents.npz')['dlatents']\n",
        "c7_50 = generate_n_images(lat)\n",
        "make_grid(c7_50, 1, 5)"
      ],
      "metadata": {
        "id": "CYfs6Cm4mQTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once generated, you can export the microstructures to a `.txt` file for further processing and analysis."
      ],
      "metadata": {
        "id": "o5eFJTqgmflh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  store_array(c7_50[i], '/content/drive/MyDrive/GAN/Vir files/generated/class_7_50_'+str(i))"
      ],
      "metadata": {
        "id": "Uw0C552mmf3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can uncomment the next cell and generate a desired microstructure using just one line of code!"
      ],
      "metadata": {
        "id": "w5yrjVKgr0T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#latent_loc = ''\n",
        "#save_loc = ''\n",
        "\n",
        "\n",
        "#store_array(generate_n_images(np.load(latent_loc)['dlatents'])[0], save_loc)"
      ],
      "metadata": {
        "id": "4ChJVqL-msAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}